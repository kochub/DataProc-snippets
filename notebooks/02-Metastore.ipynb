{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ebdd579-7dee-496d-b41c-5b77bc59d38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting session ses1\n"
     ]
    }
   ],
   "source": [
    "%create_livy_session \\\n",
    "--cluster dp-dl \\\n",
    "--id ses1 \\\n",
    "--conf spark.jars.packages=io.delta:delta-core_2.12:0.8.0 \\\n",
    "--conf spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension \\\n",
    "--conf spark.hive.metastore.uris=thrift://10.130.0.17:9083 \\\n",
    "--conf spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog \\\n",
    "--conf spark.sql.hive.metastore.sharedPrefixes=com.amazonaws,ru.yandex.cloud \\\n",
    "--conf spark.sql.warehouse.dir=s3a://keshaaa/wh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1748171-e92c-458d-9002-9d157a3c2929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[]\n"
     ]
    }
   ],
   "source": [
    "#!spark --cluster dp-dl --session ses1\n",
    "spark.sql(f\"DROP DATABASE IF EXISTS testdelta CASCADE;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deefed10-9f71-4c4e-ae75-2007a373d24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for an Apache Livy session to start...\n",
      "Apache Livy session has started.\n",
      "DataFrame[]\n"
     ]
    }
   ],
   "source": [
    "#!spark --cluster dp-dl --session ses1\n",
    "spark.sql(\"CREATE DATABASE testdelta;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f8193bfb-9bb0-42ac-92ad-f19b277a0e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "%delete_livy_session \\\n",
    "--cluster dp-dl \\\n",
    "--id ses1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff80a79e-1ec3-4081-b2a6-ee3e98284208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!spark --cluster dp-dl --session ses1\n",
    "spark.sql(\"USE testdelta;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7cc97f17-a1bc-40df-9a42-59adb73e2914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[]\n"
     ]
    }
   ],
   "source": [
    "#!spark --cluster dp-dl --session ses1\n",
    "spark.sql(\"CREATE TABLE tab1(a INTEGER NOT NULL, b VARCHAR(100)) USING DELTA;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04afb030-c42a-4d28-ad97-3bb74d0c4d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Database(name='default', description='Default Hive database', locationUri='file:/var/lib/livy/spark-warehouse'), Database(name='testdelta', description='', locationUri='s3a://keshaaa/wh/testdelta.db')]\n"
     ]
    }
   ],
   "source": [
    "#!spark --cluster dp-dl --session ses1\n",
    "spark.catalog.listDatabases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2d1dd32-349b-406c-899d-673ab5d04f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!spark --cluster dp-dl --session ses1\n",
    "spark.catalog.setCurrentDatabase('testdelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1ced0beb-782c-43f8-bbff-e811e313654c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Table(name='tab1', database='testdelta', description=None, tableType='MANAGED', isTemporary=False)]\n"
     ]
    }
   ],
   "source": [
    "#!spark --cluster dp-dl --session ses1\n",
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca00bbe-fb9a-442e-a7a2-41a7b17cb352",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!spark --cluster dp-dl --session ses1\n",
    "help(spark.catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4e256cd3-8dcd-4d29-b8ff-829ce752989f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('spark.eventLog.enabled', 'true'), ('spark.dynamicAllocation.minExecutors', '1'), ('spark.history.fs.cleaner.maxAge', '7d'), ('spark.blacklist.decommissioning.timeout', '1h'), ('spark.yarn.appMasterEnv.SPARK_PUBLIC_DNS', '$(hostname -f)'), ('spark.driver.appUIAddress', 'http://rc1a-dataproc-m-7ebpyka7j769yw12.mdb.yandexcloud.net:4040'), ('spark.executor.extraJavaOptions', \"-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:MaxHeapFreeRatio=70 -XX:+CMSClassUnloadingEnabled -XX:OnOutOfMemoryError='kill -9 %p'\"), ('spark.sql.cbo.enable', 'true'), ('spark.executor.cores', '3'), ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES', 'http://rc1a-dataproc-m-7ebpyka7j769yw12.mdb.yandexcloud.net:8088/proxy/application_1685629844963_0015'), ('spark.history.fs.cleaner.interval', '1d'), ('spark.app.startTime', '1687879540310'), ('spark.ui.filters', 'org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter'), ('spark.app.initial.jar.urls', 'spark://rc1a-dataproc-m-7ebpyka7j769yw12.mdb.yandexcloud.net:38463/jars/livy-api-0.8.0-incubating-SNAPSHOT.jar,spark://rc1a-dataproc-m-7ebpyka7j769yw12.mdb.yandexcloud.net:38463/jars/reflectasm-1.11.3.jar,spark://rc1a-dataproc-m-7ebpyka7j769yw12.mdb.yandexcloud.net:38463/jars/livy-repl_2.12-0.8.0-incubating-SNAPSHOT.jar,spark://rc1a-dataproc-m-7ebpyka7j769yw12.mdb.yandexcloud.net:38463/jars/commons-codec-1.9.jar,spark://rc1a-dataproc-m-7ebpyka7j769yw12.mdb.yandexcloud.net:38463/jars/minlog-1.3.0.jar,spark://rc1a-dataproc-m-7ebpyka7j769yw12.mdb.yandexcloud.net:38463/jars/livy-core_2.12-0.8.0-incubating-SNAPSHOT.jar,spark://rc1a-dataproc-m-7ebpyka7j769yw12.mdb.yandexcloud.net:38463/jars/livy-rsc-0.8.0-incubating-SNAPSHOT.jar,spark://rc1a-dataproc-m-7ebpyka7j769yw12.mdb.yandexcloud.net:38463/jars/netty-all-4.1.47.Final.jar,spark://rc1a-dataproc-m-7ebpyka7j769yw12.mdb.yandexcloud.net:38463/jars/asm-5.0.4.jar,spark://rc1a-dataproc-m-7ebpyka7j769yw12.mdb.yandexcloud.net:38463/jars/objenesis-2.5.1.jar'), ('spark.yarn.dist.pyFiles', 'file:///usr/lib/spark/python/lib/pyspark.zip,file:///usr/lib/spark/python/lib/py4j-0.10.9-src.zip,file:///var/lib/livy/.ivy2/jars/io.delta_delta-core_2.12-0.8.0.jar,file:///var/lib/livy/.ivy2/jars/org.antlr_antlr4-4.7.jar,file:///var/lib/livy/.ivy2/jars/org.antlr_antlr4-runtime-4.7.jar,file:///var/lib/livy/.ivy2/jars/org.antlr_antlr-runtime-3.5.2.jar,file:///var/lib/livy/.ivy2/jars/org.antlr_ST4-4.0.8.jar,file:///var/lib/livy/.ivy2/jars/org.abego.treelayout_org.abego.treelayout.core-1.0.3.jar,file:///var/lib/livy/.ivy2/jars/org.glassfish_javax.json-1.0.4.jar,file:///var/lib/livy/.ivy2/jars/com.ibm.icu_icu4j-58.2.jar'), ('spark.repl.class.uri', 'spark://rc1a-dataproc-m-7ebpyka7j769yw12.mdb.yandexcloud.net:38463/classes'), ('spark.yarn.dist.jars', 'file:///usr/lib/livy/rsc-jars/asm-5.0.4.jar,file:///usr/lib/livy/rsc-jars/minlog-1.3.0.jar,file:///usr/lib/livy/rsc-jars/livy-rsc-0.8.0-incubating-SNAPSHOT.jar,file:///usr/lib/livy/rsc-jars/objenesis-2.5.1.jar,file:///usr/lib/livy/rsc-jars/livy-api-0.8.0-incubating-SNAPSHOT.jar,file:///usr/lib/livy/rsc-jars/reflectasm-1.11.3.jar,file:///usr/lib/livy/rsc-jars/netty-all-4.1.47.Final.jar,file:///usr/lib/livy/repl_2.12-jars/livy-repl_2.12-0.8.0-incubating-SNAPSHOT.jar,file:///usr/lib/livy/repl_2.12-jars/livy-core_2.12-0.8.0-incubating-SNAPSHOT.jar,file:///usr/lib/livy/repl_2.12-jars/commons-codec-1.9.jar,file:///var/lib/livy/.ivy2/jars/io.delta_delta-core_2.12-0.8.0.jar,file:///var/lib/livy/.ivy2/jars/org.antlr_antlr4-4.7.jar,file:///var/lib/livy/.ivy2/jars/org.antlr_antlr4-runtime-4.7.jar,file:///var/lib/livy/.ivy2/jars/org.antlr_antlr-runtime-3.5.2.jar,file:///var/lib/livy/.ivy2/jars/org.antlr_ST4-4.0.8.jar,file:///var/lib/livy/.ivy2/jars/org.abego.treelayout_org.abego.treelayout.core-1.0.3.jar,file:///var/lib/livy/.ivy2/jars/org.glassfish_javax.json-1.0.4.jar,file:///var/lib/livy/.ivy2/jars/com.ibm.icu_icu4j-58.2.jar'), ('spark.hadoop.yarn.timeline-service.enabled', 'false'), ('spark.submit.pyFiles', '/usr/lib/spark/python/lib/pyspark.zip,/usr/lib/spark/python/lib/py4j-0.10.9-src.zip,/var/lib/livy/.ivy2/jars/io.delta_delta-core_2.12-0.8.0.jar,/var/lib/livy/.ivy2/jars/org.antlr_antlr4-4.7.jar,/var/lib/livy/.ivy2/jars/org.antlr_antlr4-runtime-4.7.jar,/var/lib/livy/.ivy2/jars/org.antlr_antlr-runtime-3.5.2.jar,/var/lib/livy/.ivy2/jars/org.antlr_ST4-4.0.8.jar,/var/lib/livy/.ivy2/jars/org.abego.treelayout_org.abego.treelayout.core-1.0.3.jar,/var/lib/livy/.ivy2/jars/org.glassfish_javax.json-1.0.4.jar,/var/lib/livy/.ivy2/jars/com.ibm.icu_icu4j-58.2.jar'), ('spark.executor.id', 'driver'), ('spark.driver.extraJavaOptions', \"-XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:MaxHeapFreeRatio=70 -XX:+CMSClassUnloadingEnabled -XX:OnOutOfMemoryError='kill -9 %p'\"), ('spark.yarn.secondary.jars', 'asm-5.0.4.jar,minlog-1.3.0.jar,livy-rsc-0.8.0-incubating-SNAPSHOT.jar,objenesis-2.5.1.jar,livy-api-0.8.0-incubating-SNAPSHOT.jar,reflectasm-1.11.3.jar,netty-all-4.1.47.Final.jar,livy-repl_2.12-0.8.0-incubating-SNAPSHOT.jar,livy-core_2.12-0.8.0-incubating-SNAPSHOT.jar,commons-codec-1.9.jar,io.delta_delta-core_2.12-0.8.0.jar,org.antlr_antlr4-4.7.jar,org.antlr_antlr4-runtime-4.7.jar,org.antlr_antlr-runtime-3.5.2.jar,org.antlr_ST4-4.0.8.jar,org.abego.treelayout_org.abego.treelayout.core-1.0.3.jar,org.glassfish_javax.json-1.0.4.jar,com.ibm.icu_icu4j-58.2.jar'), ('spark.app.name', 'ses1'), ('spark.sql.hive.metastore.sharedPrefixes', 'com.amazonaws,ru.yandex.cloud'), ('spark.decommissioning.timeout.threshold', '20'), ('spark.sql.catalogImplementation', 'hive'), ('spark.executorEnv.PYTHONPATH', '{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.9-src.zip<CPS>{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.9-src.zip<CPS>{{PWD}}/io.delta_delta-core_2.12-0.8.0.jar<CPS>{{PWD}}/org.antlr_antlr4-4.7.jar<CPS>{{PWD}}/org.antlr_antlr4-runtime-4.7.jar<CPS>{{PWD}}/org.antlr_antlr-runtime-3.5.2.jar<CPS>{{PWD}}/org.antlr_ST4-4.0.8.jar<CPS>{{PWD}}/org.abego.treelayout_org.abego.treelayout.core-1.0.3.jar<CPS>{{PWD}}/org.glassfish_javax.json-1.0.4.jar<CPS>{{PWD}}/com.ibm.icu_icu4j-58.2.jar'), ('spark.repl.local.jars', 'file:///usr/lib/livy/rsc-jars/asm-5.0.4.jar,file:///usr/lib/livy/rsc-jars/minlog-1.3.0.jar,file:///usr/lib/livy/rsc-jars/livy-rsc-0.8.0-incubating-SNAPSHOT.jar,file:///usr/lib/livy/rsc-jars/objenesis-2.5.1.jar,file:///usr/lib/livy/rsc-jars/livy-api-0.8.0-incubating-SNAPSHOT.jar,file:///usr/lib/livy/rsc-jars/reflectasm-1.11.3.jar,file:///usr/lib/livy/rsc-jars/netty-all-4.1.47.Final.jar,file:///usr/lib/livy/repl_2.12-jars/livy-repl_2.12-0.8.0-incubating-SNAPSHOT.jar,file:///usr/lib/livy/repl_2.12-jars/livy-core_2.12-0.8.0-incubating-SNAPSHOT.jar,file:///usr/lib/livy/repl_2.12-jars/commons-codec-1.9.jar,file:///var/lib/livy/.ivy2/jars/io.delta_delta-core_2.12-0.8.0.jar,file:///var/lib/livy/.ivy2/jars/org.antlr_antlr4-4.7.jar,file:///var/lib/livy/.ivy2/jars/org.antlr_antlr4-runtime-4.7.jar,file:///var/lib/livy/.ivy2/jars/org.antlr_antlr-runtime-3.5.2.jar,file:///var/lib/livy/.ivy2/jars/org.antlr_ST4-4.0.8.jar,file:///var/lib/livy/.ivy2/jars/org.abego.treelayout_org.abego.treelayout.core-1.0.3.jar,file:///var/lib/livy/.ivy2/jars/org.glassfish_javax.json-1.0.4.jar,file:///var/lib/livy/.ivy2/jars/com.ibm.icu_icu4j-58.2.jar'), ('spark.jars', 'file:/usr/lib/livy/rsc-jars/asm-5.0.4.jar,file:/usr/lib/livy/rsc-jars/minlog-1.3.0.jar,file:/usr/lib/livy/rsc-jars/livy-rsc-0.8.0-incubating-SNAPSHOT.jar,file:/usr/lib/livy/rsc-jars/objenesis-2.5.1.jar,file:/usr/lib/livy/rsc-jars/livy-api-0.8.0-incubating-SNAPSHOT.jar,file:/usr/lib/livy/rsc-jars/reflectasm-1.11.3.jar,file:/usr/lib/livy/rsc-jars/netty-all-4.1.47.Final.jar,file:/usr/lib/livy/repl_2.12-jars/livy-repl_2.12-0.8.0-incubating-SNAPSHOT.jar,file:/usr/lib/livy/repl_2.12-jars/livy-core_2.12-0.8.0-incubating-SNAPSHOT.jar,file:/usr/lib/livy/repl_2.12-jars/commons-codec-1.9.jar'), ('spark.driver.host', 'rc1a-dataproc-m-7ebpyka7j769yw12.mdb.yandexcloud.net'), ('spark.yarn.am.cores', '1'), ('spark.dynamicAllocation.timeout', '1h'), ('spark.driver.maxResultSize', '2560m'), ('spark.yarn.submit.waitAppCompletion', 'false'), ('spark.ui.proxyBase', '/proxy/application_1685629844963_0015'), ('spark.yarn.am.memory', '640m'), ('spark.repl.class.outputDir', '/tmp/spark3282885078910353411'), ('spark.yarn.maxAppAttempts', '1'), ('spark.yarn.dist.archives', ''), ('spark.yarn.historyServer.address', 'rc1a-dataproc-m-7ebpyka7j769yw12.mdb.yandexcloud.net:18080'), ('spark.submit.deployMode', 'client'), ('spark.driver.cores', '1'), ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS', 'rc1a-dataproc-m-7ebpyka7j769yw12.mdb.yandexcloud.net'), ('spark.livy.spark_major_version', '3'), ('spark.driver.memory', '5120m'), ('spark.sql.warehouse.dir', 's3a://keshaaa/wh'), ('spark.history.ui.port', '18080'), ('spark.shuffle.service.enabled', 'true'), ('spark.yarn.tags', 'livy-session-23-pe4AjSw8'), ('spark.resourceManager.cleanupExpiredHost', 'true'), ('spark.stage.attempt.ignoreOnDecommissionFetchFailure', 'True'), ('spark.dynamicAllocation.maxExecutors', '8192'), ('spark.history.fs.cleaner.enabled', 'true'), ('spark.history.fs.logDirectory', 's3a://keshaaa/dataproc/hadoop/var/log/spark/apps'), ('spark.yarn.jars', 'local:/usr/lib/spark/jars/*,local:/usr/lib/spark/external/lib/*'), ('spark.driver.port', '38463'), ('spark.master', 'yarn'), ('spark.executor.memory', '10138m'), ('spark.sql.extensions', 'io.delta.sql.DeltaSparkSessionExtension'), ('spark.eventLog.dir', 's3a://keshaaa/dataproc/hadoop/var/log/spark/apps'), ('spark.jars.packages', 'io.delta:delta-core_2.12:0.8.0'), ('spark.dynamicAllocation.enabled', 'true'), ('spark.yarn.isPython', 'true'), ('spark.files.fetchFailure.unRegisterOutputOnHost', 'True'), ('spark.app.id', 'application_1685629844963_0015'), ('spark.sql.catalog.spark_catalog', 'org.apache.spark.sql.delta.catalog.DeltaCatalog'), ('spark.blacklist.decommissioning.enabled', 'true')]\n"
     ]
    }
   ],
   "source": [
    "#!spark --cluster dp-dl --session ses1\n",
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "62c12ede-f827-4da3-8764-abc2ea693a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/conf.py\", line 51, in get\n",
      "    return self._jconf.get(key)\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py\", line 128, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 326, in get_return_value\n",
      "    raise Py4JJavaError(\n",
      "py4j.protocol.Py4JJavaError: An error occurred while calling o91.get.\n",
      ": java.util.NoSuchElementException: spark.rpc.message.maxSize\n",
      "\tat org.apache.spark.sql.internal.SQLConf.$anonfun$getConfString$3(SQLConf.scala:3256)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.internal.SQLConf.getConfString(SQLConf.scala:3256)\n",
      "\tat org.apache.spark.sql.RuntimeConfig.get(RuntimeConfig.scala:73)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-e0e213eca109>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexecute_livy_statement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://10.128.0.30:8998/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ses1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\nspark.conf.get('spark.rpc.message.maxSize')\\n#\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'EMPTY_LOAD'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/kernel/lib/python3.8/site-packages/ml_kernel/magics/livy_executor.py\u001b[0m in \u001b[0;36mexecute_livy_statement\u001b[0;34m(self, url, session_name, variable_identifiers, return_variables, code, state_load_type)\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mexecute_statement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_import_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecute_statement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_export_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecute_statement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kernel/lib/python3.8/site-packages/ml_kernel/magics/livy_executor.py\u001b[0m in \u001b[0;36mexecute_statement\u001b[0;34m(code)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mexecute_statement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_statement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvariables_import_code\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kernel/lib/python3.8/site-packages/ml_kernel/magics/livy_executor.py\u001b[0m in \u001b[0;36m_create_statement\u001b[0;34m(self, url, session_id, code)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'status'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'error'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'traceback'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unexpected output status: {output['status']}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!spark --cluster dp-dl --session ses1\n",
    "spark.conf.get('spark.rpc.message.maxSize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ca4c542d-cee2-4dfa-84b1-4ade93025ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_jconf': JavaObject id=o91}\n"
     ]
    }
   ],
   "source": [
    "#!spark --cluster dp-dl --session ses1\n",
    "print(spark.conf.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51608ab0-b45e-4ca1-99c1-cdeccdd65f05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "edb5a54c-3815-4057-8e6e-a729e2b11dc3",
  "notebookPath": "modern-data-lake-storage-layers/notebooks/03-Metastore.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
