{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17a952b7-0703-4b42-8da4-83425e2ab90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting session ses1\n"
     ]
    }
   ],
   "source": [
    "%create_livy_session \\\n",
    "--cluster ephemeral-cluster \\\n",
    "--id ses1 \\\n",
    "--conf spark.jars.packages=io.delta:delta-core_2.12:0.8.0 \\\n",
    "--conf spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension \\\n",
    "--conf spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog \\\n",
    "--conf spark.sql.hive.metastore.sharedPrefixes=com.amazonaws,ru.yandex.cloud \\\n",
    "--conf spark.sql.warehouse.dir=s3a://keshaaa/wh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ee4ea5c8-2c57-48c9-855e-38f28b3da637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!spark --cluster ephemeral-cluster --session ses1\n",
    "S3_BUCKET_NAME=\"keshaaa\"\n",
    "inputDF = spark.createDataFrame(\n",
    "    [\n",
    "        (\"100\", \"2015-01-01\", \"2015-01-01T13:51:39.340396Z\"),\n",
    "        (\"101\", \"2015-01-01\", \"2015-01-01T12:14:58.597216Z\"),\n",
    "        (\"102\", \"2015-01-01\", \"2015-01-01T13:51:40.417052Z\"),\n",
    "        (\"103\", \"2015-01-01\", \"2015-01-01T13:51:40.519832Z\"),\n",
    "        (\"104\", \"2015-01-02\", \"2015-01-01T12:15:00.512679Z\"),\n",
    "        (\"105\", \"2015-01-02\", \"2015-01-01T13:51:42.248818Z\"),\n",
    "    ],\n",
    "    [\"id\", \"creation_date\", \"last_update_time\"],\n",
    ")\n",
    "\n",
    "# Write a DataFrame as a Delta dataset\n",
    "inputDF.write.format(\"delta\").mode(\"overwrite\").option(\n",
    "    \"overwriteSchema\", \"true\"\n",
    ").partitionBy(\"creation_date\").save(f\"s3a://{S3_BUCKET_NAME}/tmp/delta/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b84ec193-cd45-4080-9a89-01e953eb2067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/datasphere/s3/s3fs/tmp/delta:\n",
      "total 0\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "ls -lR /home/jupyter/datasphere/s3/s3fs/tmp/delta | tee /tmp/delta_op_001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "48867bf5-9dbe-4bee-b0eb-200877de1ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+--------------------+\n",
      "| id|creation_date|    last_update_time|\n",
      "+---+-------------+--------------------+\n",
      "|100|   2022-01-11|2015-01-01T13:51:...|\n",
      "|103|   2015-01-01|2015-01-01T13:51:...|\n",
      "|101|   2015-01-01|2015-01-01T12:14:...|\n",
      "|102|   2015-01-01|2015-01-01T13:51:...|\n",
      "|104|   2015-01-02|2015-01-01T12:15:...|\n",
      "|105|   2015-01-02|2015-01-01T13:51:...|\n",
      "+---+-------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "#!spark --cluster ephemeral-cluster --session ses1\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# Create a new DataFrame from the first row of inputDF with a different creation_date value\n",
    "updateDF = inputDF.where(\"id = 100\").withColumn(\"creation_date\", lit(\"2022-01-11\"))\n",
    "\n",
    "from delta.tables import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "deltaTable = DeltaTable.forPath(spark, f\"s3a://{S3_BUCKET_NAME}/tmp/delta/\")\n",
    "\n",
    "deltaTable.alias(\"oldData\") \\\n",
    "  .merge(\n",
    "    updateDF.alias(\"newData\"),\n",
    "    \"oldData.id = newData.id\") \\\n",
    "  .whenMatchedUpdate(set = { \"creation_date\": col(\"newData.creation_date\") }) \\\n",
    "  .execute()\n",
    "\n",
    "deltaTable.toDF().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f8f5b281-a50f-4e3b-b642-27f5d146190b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+--------------------+\n",
      "| id|creation_date|    last_update_time|\n",
      "+---+-------------+--------------------+\n",
      "|100|   2015-01-01|2015-01-01T13:51:...|\n",
      "|101|   2015-01-01|2015-01-01T12:14:...|\n",
      "|102|   2015-01-01|2015-01-01T13:51:...|\n",
      "|103|   2015-01-01|2015-01-01T13:51:...|\n",
      "|104|   2015-01-02|2015-01-01T12:15:...|\n",
      "|105|   2015-01-02|2015-01-01T13:51:...|\n",
      "+---+-------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "#!spark --cluster ephemeral-cluster --session ses1\n",
    "inputDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "34fceca2-4db4-4932-9435-02ff0d4e600b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+\n",
      "|version|          timestamp|userId|userName|operation| operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|    operationMetrics|userMetadata|\n",
      "+-------+-------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+\n",
      "|      1|2023-07-03 16:55:00|  null|    null|    MERGE|[predicate -> (ol...|null|    null|     null|          0|          null|        false|[numTargetRowsCop...|        null|\n",
      "|      0|2023-07-03 16:54:28|  null|    null|    WRITE|[mode -> Overwrit...|null|    null|     null|       null|          null|        false|[numFiles -> 3, n...|        null|\n",
      "+-------+-------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "#!spark --cluster ephemeral-cluster --session ses1\n",
    "deltaTable.history().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3646a976-7d1a-47f9-997e-179b3de68aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+\n",
      "|version|          timestamp|userId|userName|operation| operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|    operationMetrics|userMetadata|\n",
      "+-------+-------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+\n",
      "|      1|2023-07-03 16:55:00|  null|    null|    MERGE|[predicate -> (ol...|null|    null|     null|          0|          null|        false|[numTargetRowsCop...|        null|\n",
      "|      0|2023-07-03 16:54:28|  null|    null|    WRITE|[mode -> Overwrit...|null|    null|     null|       null|          null|        false|[numFiles -> 3, n...|        null|\n",
      "+-------+-------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+\n",
      "\n",
      "Latest version is: 1\n"
     ]
    }
   ],
   "source": [
    "#!spark --cluster ephemeral-cluster --session ses1\n",
    "history = spark.sql(f\"DESCRIBE HISTORY delta.`s3a://{S3_BUCKET_NAME}/tmp/delta/`\")\n",
    "history.show()\n",
    "\n",
    "latest_version = history.selectExpr(\"max(version)\").collect()[0][0]\n",
    "print(f\"Latest version is: {latest_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9eac0fe9-8454-4678-bb26-568fe48e8cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+--------------------+\n",
      "| id|creation_date|    last_update_time|\n",
      "+---+-------------+--------------------+\n",
      "|100|   2015-01-01|2015-01-01T13:51:...|\n",
      "|101|   2015-01-01|2015-01-01T12:14:...|\n",
      "|102|   2015-01-01|2015-01-01T13:51:...|\n",
      "|103|   2015-01-01|2015-01-01T13:51:...|\n",
      "|104|   2015-01-02|2015-01-01T12:15:...|\n",
      "|105|   2015-01-02|2015-01-01T13:51:...|\n",
      "+---+-------------+--------------------+\n",
      "\n",
      "+---+-------------+--------------------+\n",
      "| id|creation_date|    last_update_time|\n",
      "+---+-------------+--------------------+\n",
      "|100|   2022-01-11|2015-01-01T13:51:...|\n",
      "|101|   2015-01-01|2015-01-01T12:14:...|\n",
      "|102|   2015-01-01|2015-01-01T13:51:...|\n",
      "|103|   2015-01-01|2015-01-01T13:51:...|\n",
      "|104|   2015-01-02|2015-01-01T12:15:...|\n",
      "|105|   2015-01-02|2015-01-01T13:51:...|\n",
      "+---+-------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "#!spark --cluster ephemeral-cluster --session ses1\n",
    "df2 = (\n",
    "    spark.read.format(\"delta\")\n",
    "    .option(\"versionAsOf\", 0)\n",
    "    .load(f\"s3a://{S3_BUCKET_NAME}/tmp/delta/\")\n",
    ")\n",
    "df2.sort(\"id\").show()\n",
    "df2 = (\n",
    "    spark.read.format(\"delta\")\n",
    "    .option(\"versionAsOf\", 1)\n",
    "    .load(f\"s3a://{S3_BUCKET_NAME}/tmp/delta/\")\n",
    ")\n",
    "df2.sort(\"id\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c30f15c0-d323-4d36-8820-5fc2e35156dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[path: string]\n"
     ]
    }
   ],
   "source": [
    "#!spark --cluster ephemeral-cluster --session ses1\n",
    "spark.sql(f\"VACUUM delta.`s3a://{S3_BUCKET_NAME}/tmp/delta/`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d0e78eb3-e4f9-47e7-b368-d11f44370742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/datasphere/s3/s3fs/tmp/delta:\n",
      "total 2\n",
      "drwxrwxrwx 1 root root 0 Jan  1  1970 _delta_log\n",
      "drwxrwxrwx 1 root root 0 Jan  1  1970 creation_date=2015-01-01\n",
      "drwxrwxrwx 1 root root 0 Jan  1  1970 creation_date=2015-01-02\n",
      "drwxrwxrwx 1 root root 0 Jan  1  1970 creation_date=2022-01-11\n",
      "\n",
      "/home/jupyter/datasphere/s3/s3fs/tmp/delta/_delta_log:\n",
      "total 3\n",
      "-rwxrwxrwx 1 root root 1451 Jul  3 16:54 00000000000000000000.json\n",
      "-rwxrwxrwx 1 root root 1461 Jul  3 16:55 00000000000000000001.json\n",
      "\n",
      "/home/jupyter/datasphere/s3/s3fs/tmp/delta/creation_date=2015-01-01:\n",
      "total 4\n",
      "-rwxrwxrwx 1 root root 793 Jul  3 16:54 part-00000-5e6ff72f-54e3-4f5f-8c18-ec203ff86455.c000.snappy.parquet\n",
      "-rwxrwxrwx 1 root root 875 Jul  3 16:54 part-00001-ae426758-da19-46cf-9e9b-b4b1fdd2653d.c000.snappy.parquet\n",
      "-rwxrwxrwx 1 root root 875 Jul  3 16:54 part-00011-475a45c6-2216-4362-a031-70e9518a46ec.c000.snappy.parquet\n",
      "-rwxrwxrwx 1 root root 875 Jul  3 16:54 part-00088-ed714df7-40f6-4198-876c-cd424c50cdb0.c000.snappy.parquet\n",
      "\n",
      "/home/jupyter/datasphere/s3/s3fs/tmp/delta/creation_date=2015-01-02:\n",
      "total 1\n",
      "-rwxrwxrwx 1 root root 766 Jul  3 16:54 part-00001-7b2036a8-ab4a-40d8-af5d-c2bcfbea629b.c000.snappy.parquet\n",
      "\n",
      "/home/jupyter/datasphere/s3/s3fs/tmp/delta/creation_date=2022-01-11:\n",
      "total 1\n",
      "-rwxrwxrwx 1 root root 875 Jul  3 16:54 part-00051-4bff1042-047f-4e72-bac6-342c6afeb03b.c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "ls -lR /home/jupyter/datasphere/s3/s3fs/tmp/delta | tee /tmp/delta_op_002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489a5359-022e-4746-a2da-ae23af98278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%delete_livy_session \\\n",
    "--cluster ephemeral-cluster \\\n",
    "--id ses1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
